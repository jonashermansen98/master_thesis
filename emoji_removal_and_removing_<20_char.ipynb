{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e27dab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('~/Library/Mobile Documents/com~apple~CloudDocs/UNI-kopi 2/Kandidat/virtual_environments/data/google_translate_all.csv')\n",
    "data2 = pd.read_csv('~/Library/Mobile Documents/com~apple~CloudDocs/UNI-kopi 2/Kandidat/virtual_environments/data/google_translate_all_2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cecaf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Country                  0\n",
      "City                      0\n",
      "Courier_ID                0\n",
      "First_Delivery_Date      11\n",
      "Feedback_ID               0\n",
      "Feedback_Date             0\n",
      "Weekly_Satisfaction    5228\n",
      "Rating_Application     2675\n",
      "Rating Support         2675\n",
      "Rating_Venues          2675\n",
      "Comment                   0\n",
      "translated_Comment      319\n",
      "dtype: int64\n",
      " Country                  0\n",
      "City                      0\n",
      "Courier_ID                0\n",
      "First_Delivery_Date       1\n",
      "Feedback_ID               0\n",
      "Feedback_Date             0\n",
      "Weekly_Satisfaction    4057\n",
      "Rating_Application     2023\n",
      "Rating Support         2023\n",
      "Rating_Venues          2023\n",
      "Comment                   0\n",
      "translated_Comment      229\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NAs in every column\n",
    "print(data.isna().sum())\n",
    "print(data2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08bc91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with NA in translated_Comment\n",
    "na_translated_comment_data = data[data['translated_Comment'].isna()]\n",
    "na_translated_comment_data2 = data2[data2['translated_Comment'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe03e1e",
   "metadata": {},
   "source": [
    "translated comments with NAs are comments which only contains emojies. This have been translated to empty string and replaced with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2796f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NA in translated_Comment\n",
    "data = data.dropna(subset=['translated_Comment'])\n",
    "data2 = data2.dropna(subset=['translated_Comment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "715b0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 7584\n",
      "Length of data2: 5851\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of data:\", len(data))\n",
    "print(\"Length of data2:\", len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a55847",
   "metadata": {},
   "source": [
    "Now I inspect in the two datasets, to get an overview of emojies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55538e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with emojis in 'data': 1002\n",
      "Number of rows with emojis in 'data2': 824\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains emojis\n",
    "def contains_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "# Count rows with emojis in the 'Comment' column\n",
    "emoji_rows_count = data['Comment'].apply(contains_emoji).sum()\n",
    "print(f\"Number of rows with emojis in 'data': {emoji_rows_count}\")\n",
    "\n",
    "emoji_rows_count2 = data2['Comment'].apply(contains_emoji).sum()\n",
    "print(f\"Number of rows with emojis in 'data2': {emoji_rows_count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889eec5",
   "metadata": {},
   "source": [
    "Now I remove emojies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b90687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Define the emoji removal function\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# Apply to your dataset\n",
    "data[\"translated_Comment\"] = data[\"translated_Comment\"].apply(remove_emojis)\n",
    "data2[\"translated_Comment\"] = data2[\"translated_Comment\"].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecdb38e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with emojis in 'data': 0\n",
      "Number of rows with emojis in 'data2': 0\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a text contains emojis\n",
    "def contains_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "# Count rows with emojis in the 'Comment' column\n",
    "emoji_rows_count = data['translated_Comment'].apply(contains_emoji).sum()\n",
    "print(f\"Number of rows with emojis in 'data': {emoji_rows_count}\")\n",
    "\n",
    "emoji_rows_count2 = data2['translated_Comment'].apply(contains_emoji).sum()\n",
    "print(f\"Number of rows with emojis in 'data2': {emoji_rows_count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3366566",
   "metadata": {},
   "source": [
    "All emojies are now gone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99db05",
   "metadata": {},
   "source": [
    "Since emojies were replaced with \"\", there might be double space some places. This should be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "066c8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra/double spaces in the translated_Comment column\n",
    "data[\"translated_Comment\"] = data[\"translated_Comment\"].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "data2[\"translated_Comment\"] = data2[\"translated_Comment\"].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf5aa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"comment_length\"] = data[\"translated_Comment\"].str.len()\n",
    "long_docs_data = data[data[\"comment_length\"] > 1_000_000]\n",
    "\n",
    "data2[\"comment_length\"] = data2[\"translated_Comment\"].str.len()\n",
    "long_docs_data2 = data2[data2[\"comment_length\"] > 1_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1:\n",
      "Longest document: 3604\n",
      "Shortest document: 1\n",
      "Average length: 106\n",
      "\n",
      "Dataset 2:\n",
      "Longest document: 3989\n",
      "Shortest document: 1\n",
      "Average length: 124\n"
     ]
    }
   ],
   "source": [
    "# checks the lengths of the feedbacks for first dataset\n",
    "documents = data[\"translated_Comment\"].tolist()\n",
    "doc_lengths = [len(doc) for doc in documents]\n",
    "print(\"Dataset 1:\")\n",
    "print(f\"Longest document: {max(doc_lengths)}\")\n",
    "print(f\"Shortest document: {min(doc_lengths)}\")\n",
    "print(f\"Average length: {sum(doc_lengths) // len(documents)}\")\n",
    "\n",
    "# # checks the lengths of the feedbacks for second dataset\n",
    "documents2 = data2[\"translated_Comment\"].tolist()\n",
    "doc_lengths2 = [len(doc) for doc in documents2]\n",
    "print(\"\\nDataset 2:\")\n",
    "print(f\"Longest document: {max(doc_lengths2)}\")\n",
    "print(f\"Shortest document: {min(doc_lengths2)}\")\n",
    "print(f\"Average length: {sum(doc_lengths2) // len(documents2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb13f1",
   "metadata": {},
   "source": [
    "## Drop feedback with less than 20 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a813002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 7584\n",
      "Length of data2: 5851\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of data:\", len(data))\n",
    "print(\"Length of data2:\", len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449736d",
   "metadata": {},
   "source": [
    "drop all comments with less than 20 characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897a3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['translated_Comment'].str.len() >= 20]\n",
    "data2 = data2[data2['translated_Comment'].str.len() >= 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bf38d",
   "metadata": {},
   "source": [
    "see how many feedbacks are left en the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf51eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 5826\n",
      "Length of data2: 4638\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of data:\", len(data))\n",
    "print(\"Length of data2:\", len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('~/Library/Mobile Documents/com~apple~CloudDocs/UNI-kopi 2/Kandidat/virtual_environments/data/short.csv', index=False, encoding=\"utf-8\")\n",
    "data2.to_csv('~/Library/Mobile Documents/com~apple~CloudDocs/UNI-kopi 2/Kandidat/virtual_environments/data/short_2023.csv', index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python duplicate_removal",
   "language": "python",
   "name": "duplicate_removal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
